{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aV1vLJFt_yyH"
   },
   "source": [
    "# Building an Agent with Generative Models and Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (1.102.0)\n",
      "Requirement already satisfied: pinecone in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (7.3.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (from pinecone) (2025.8.3)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (from pinecone) (0.0.7)\n",
      "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (from pinecone) (1.7.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (from pinecone) (2.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (from pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (2.32.5)\n",
      "Requirement already satisfied: packaging<25.0,>=24.2 in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (24.2)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.4.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install openai pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import re\n",
    "from copy import copy\n",
    "from functools import lru_cache\n",
    "\n",
    "import sys\n",
    "from io import StringIO\n",
    "from typing import Dict, Optional, Any\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import re\n",
    "from copy import copy\n",
    "\n",
    "import sys\n",
    "from io import StringIO\n",
    "from typing import Dict, Optional, Any\n",
    "import os\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Tuple\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url: str = userdata.get('SUPABASE_URL')\n",
    "# key: str = userdata.get('SUPABASE_API_KEY')\n",
    "# supabase: Client = create_client(url, key)\n",
    "\n",
    "# Initialize the OpenAI client with the API key from user data\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv('OPENAI_API_KEY')\n",
    ")\n",
    "\n",
    "class ChatLLM(BaseModel):\n",
    "    # Wrapper on top of OpenAI API\n",
    "    model: str = 'gpt-4o'\n",
    "    temperature: float = 0.0\n",
    "\n",
    "    def generate(self, prompt: str, stop: List[str] = None):\n",
    "        response = client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=self.temperature,\n",
    "            stop=stop\n",
    "        )\n",
    "        # Insert cost projection into postgre db \n",
    "\n",
    "        # supabase.table('cost_projecting').insert({\n",
    "        #     'prompt': prompt,\n",
    "        #     'response': response.choices[0].message.content,\n",
    "        #     'input_tokens': response.usage.prompt_tokens,\n",
    "        #     'output_tokens': response.usage.completion_tokens,\n",
    "        #     'model': self.model,\n",
    "        #     'inference_params' : {\n",
    "        #         'temperature': self.temperature,\n",
    "        #         'stop': stop\n",
    "        #     },\n",
    "        #     'is_openai': True,\n",
    "        #     'app': 'RAG'\n",
    "        # }).execute()\n",
    "\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last update, the president of Turkey is Recep Tayyip ErdoÄŸan. He has been in office since August 28, 2014. However, please verify with a current source, as political positions can change.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatLLM()\n",
    "result = llm.generate(prompt='Who is the president of Turkey?')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "# Retrieve the Pinecone API key from user data\n",
    "pinecone_key = os.getenv('PINECONE_API_KEY')\n",
    "\n",
    "# Define constants for the Pinecone index, namespace, and engine\n",
    "INDEX_NAME = 'semantic-search-rag'  # The name of the Pinecone index\n",
    "NAMESPACE = 'default'  # The namespace to use within the index\n",
    "ENGINE = 'text-embedding-3-small'  # The embedding model to use (vector size 1,536)\n",
    "\n",
    "# Initialize the Pinecone client with the retrieved API key\n",
    "pc = Pinecone(\n",
    "    api_key=pinecone_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# helper functions to get embedding from the OpenAI API\n",
    "def get_embedding(texts, engine=ENGINE):\n",
    "    response = client.embeddings.create(\n",
    "        input=texts,\n",
    "        model=engine\n",
    "    )\n",
    "\n",
    "    return response.data[0].embedding\n",
    "\n",
    "\n",
    "\n",
    "len(get_embedding('hi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pnoras/Repositories/python/nlp/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pinecone.db_data.index.Index at 0x11e366980>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if INDEX_NAME not in pc.list_indexes().names():  # need to create the index\n",
    "    print(f'Creating index {INDEX_NAME}')\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,  # The name of the index\n",
    "        dimension=1536,  # The dimensionality of the vectors for our OpenAI embedder\n",
    "        metric='cosine',  # The similarity metric to use when searching the index\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Store the index as a variable\n",
    "index = pc.Index(name=INDEX_NAME)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date_uploaded': '2025-08-31T10:07:55.396448+00:00',\n",
       " 'text': '\\n\\n\\n\\nYouâ€™re offline. This is a read only version of the page.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n  \\n\\n\\n\\n\\n\\n\\n\\nProtect Yourself from Scams \\n\\n\\n\\n \\n\\n \\n\\n\\n\\n\\nProtect Yourself from Scams\\n\\n\\n\\nSkip to main content Social Security Search  Menu  EspaÃ±ol  Sign in\\n\\n\\n\\n\\nFrequently Asked Questions\\n\\n\\n\\n\\nLast Modified: \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFAQ Home\\n\\n\\nTopics\\n\\n\\r\\n\\t\\t\\t\\t\\tKA-01735\\r\\n\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n Print\\n\\n\\n\\nHow do I get a replacement Medicare card? \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nViews: \\n\\n\\n\\nIf your Medicare card was lost, stolen, or destroyed, you can request a replacement online at Medicare.gov.\\nYou can print an official copy of your card from your online Medicare account \\nor call 1-800-MEDICARE (1-800-633-4227 TTY 1-877-486-2048) to order a replacement card to be sent in the mail.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFooter menu\\n\\n\\n\\n\\n\\n\\n\\n\\nGive us Feedback.\\n\\nDid this answer your question?\\n\\nNo\\nYes\\nNo\\n\\nThanks for your feedback.\\n\\n\\n\\n\\n\\n\\n',\n",
       " 'url': 'https://faq.ssa.gov/en-us/Topic/article/KA-01735'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def query_from_pinecone(query, top_k=3, include_metadata=True):\n",
    "    # get embedding from THE SAME embedder as the documents\n",
    "    query_embedding = get_embedding(query, engine=ENGINE)\n",
    "\n",
    "    return index.query(\n",
    "      vector=query_embedding,\n",
    "      top_k=top_k,\n",
    "      namespace=NAMESPACE,\n",
    "      include_metadata=include_metadata   # gets the metadata (dates, text, etc)\n",
    "    ).get('matches')\n",
    "\n",
    "query_from_pinecone('I lost my medicare card')[0]['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_ANSWER_TOKEN = \"Assistant Response:\"\n",
    "STOP = '[END]'\n",
    "PROMPT_TEMPLATE = \"\"\"Today is {today} and you can retrieve information from a database. Response the user's input as best as you can.\n",
    "\n",
    "Here is an example of the conversation format:\n",
    "\n",
    "[START]\n",
    "User Input: the input question you must answer\n",
    "Context: retrieved context from the database\n",
    "Context URL: context url\n",
    "Context Score : a score from 0 - 1 of how strong the information is a match\n",
    "Assistant Thought: This context has sufficient information to answer the question.\n",
    "Assistant Response: your final answer to the original input question which could be I don't have sufficient information to answer the question and you should add the context url if having sufficient information.\n",
    "[END]\n",
    "[START]\n",
    "User Input: another input question you must answer\n",
    "Context: more retrieved context from the database\n",
    "Context URL: context url\n",
    "Context Score : another score from 0 - 1 of how strong the information is a match\n",
    "Assistant Thought: This context does not have sufficient information to answer the question.\n",
    "Assistant Response: your final answer to the second input question which could be I don't have sufficient information to answer the question. and you should add the context url if having sufficient information. \n",
    "[END]\n",
    "[START]\n",
    "User Input: another input question you must answer\n",
    "Context: NO CONTEXT FOUND\n",
    "Context URL: NONE\n",
    "Context Score : 0\n",
    "Assistant Thought: We either could not find something or we don't need to look something up\n",
    "Assistant Response: Reason through the best way to answer\n",
    "[END]\n",
    "\n",
    "Begin:\n",
    "\n",
    "{running_convo} \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RagBot(BaseModel):\n",
    "    llm: ChatLLM\n",
    "    prompt_template: str = PROMPT_TEMPLATE\n",
    "    stop_pattern: List[str] = [STOP]\n",
    "    user_inputs: List[str] = []\n",
    "    ai_responses: List[str] = []\n",
    "    contexts: List[Tuple[str,float]] = []\n",
    "    verbose: bool = False\n",
    "    threshold: float = 0.6\n",
    "\n",
    "    def query_from_pinecone(self, query: str, top_k: int = 3, include_metadata: bool = True) -> List[Tuple[str,float]]:\n",
    "        \"\"\"Query Pinecone for the most relevant contexts\"\"\"\n",
    "        return query_from_pinecone(query, top_k, include_metadata)\n",
    "    \n",
    "    @property\n",
    "    def running_convo(self):\n",
    "        convo = ''\n",
    "        for index in range(len(self.user_inputs)):\n",
    "            convo += f'[START]\\nUser Input: {self.user_inputs[index]}\\n'\n",
    "            convo += f'Context: {self.contexts[index][0]}\\nContext URL: {self.contexts[index][1]}\\nContext Score: {self.contexts[index][2]}'\n",
    "\n",
    "            if len(self.ai_responses) > index:\n",
    "                convo += self.ai_responses[index]\n",
    "                convo += '\\n[END]\\n'\n",
    "        return convo\n",
    "    \n",
    "    def run(self, question: str) -> str:\n",
    "        \"\"\"Run the RAG bot\"\"\"\n",
    "        \n",
    "        self.user_inputs.append(question)\n",
    "        top_response = self.query_from_pinecone(question)[0]\n",
    "\n",
    "        print(top_response['score'])\n",
    "\n",
    "        if top_response['score'] > self.threshold:\n",
    "            self.contexts.append(\n",
    "                (top_response['metadata']['text'], top_response['metadata']['url'], top_response['score'])\n",
    "            )  \n",
    "        \n",
    "        else:\n",
    "            self.contexts.append(\n",
    "                ('NO CONTEXT FOUND', 'NONE', 0)\n",
    "            )\n",
    "        \n",
    "        prompt = self.prompt_template.format(\n",
    "            today=datetime.datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "            running_convo=self.running_convo\n",
    "        )\n",
    "\n",
    "        if self.verbose:\n",
    "            print('-------')\n",
    "            print('PROMPT')\n",
    "            print('-------')\n",
    "            print(prompt)\n",
    "            print('-------')\n",
    "\n",
    "        generated = self.llm.generate(prompt, self.stop_pattern)\n",
    "\n",
    "        if self.verbose:\n",
    "            print('-------')\n",
    "            print('GENERATED')\n",
    "            print('-------')\n",
    "            print(generated)\n",
    "            print('-------')\n",
    "\n",
    "        self.ai_responses.append(generated)\n",
    "        if FINAL_ANSWER_TOKEN in generated:\n",
    "            generated = generated.split(FINAL_ANSWER_TOKEN)[-1]\n",
    "\n",
    "        return generated         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.693827927\n",
      " If your Medicare card was lost, stolen, or destroyed, you can request a replacement online at Medicare.gov. You can also print an official copy of your card from your online Medicare account or call 1-800-MEDICARE (1-800-633-4227 TTY 1-877-486-2048) to order a replacement card to be sent in the mail. For more information, you can visit [this link](https://faq.ssa.gov/en-us/Topic/article/KA-01735).\n"
     ]
    }
   ],
   "source": [
    "r = RagBot(llm=ChatLLM(temperature=0.0), stop_pattern=['[END]'])\n",
    "print(r.run('I lost my medicare card'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START]\n",
      "User Input: I lost my medicare card\n",
      "Context: \n",
      "\n",
      "\n",
      "\n",
      "Youâ€™re offline. This is a read only version of the page.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to content\n",
      "\n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Protect Yourself from Scams \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Protect Yourself from Scams\n",
      "\n",
      "\n",
      "\n",
      "Skip to main content Social Security Search  Menu  EspaÃ±ol  Sign in\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Frequently Asked Questions\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Last Modified: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FAQ Home\n",
      "\n",
      "\n",
      "Topics\n",
      "\n",
      "\n",
      "\t\t\t\t\tKA-01735\n",
      "\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Print\n",
      "\n",
      "\n",
      "\n",
      "How do I get a replacement Medicare card? \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Views: \n",
      "\n",
      "\n",
      "\n",
      "If your Medicare card was lost, stolen, or destroyed, you can request a replacement online at Medicare.gov.\n",
      "You can print an official copy of your card from your online Medicare account \n",
      "or call 1-800-MEDICARE (1-800-633-4227 TTY 1-877-486-2048) to order a replacement card to be sent in the mail.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Footer menu\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Give us Feedback.\n",
      "\n",
      "Did this answer your question?\n",
      "\n",
      "No\n",
      "Yes\n",
      "No\n",
      "\n",
      "Thanks for your feedback.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Context URL: https://faq.ssa.gov/en-us/Topic/article/KA-01735\n",
      "Context Score: 0.693827927Assistant Thought: This context has sufficient information to answer the question.\n",
      "Assistant Response: If your Medicare card was lost, stolen, or destroyed, you can request a replacement online at Medicare.gov. You can also print an official copy of your card from your online Medicare account or call 1-800-MEDICARE (1-800-633-4227 TTY 1-877-486-2048) to order a replacement card to be sent in the mail. For more information, you can visit [this link](https://faq.ssa.gov/en-us/Topic/article/KA-01735).\n",
      "[END]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(r.running_convo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
